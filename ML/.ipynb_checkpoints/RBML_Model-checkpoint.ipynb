{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas_profiling'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c81e2fb61f63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas_profiling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas_profiling'"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import os\n",
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import plot_confusion_matrix, confusion_matrix\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas_profiling\n",
    "\n",
    "\n",
    "from scipy.stats import skew, norm\n",
    "from scipy import stats\n",
    "from scipy.special import boxcox1p\n",
    "from sklearn.preprocessing import LabelEncoder, PolynomialFeatures, RobustScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import ElasticNetCV, ElasticNet, LinearRegression, Lasso, LassoCV, Ridge, RidgeCV, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor, AdaBoostClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_squared_log_error, classification_report, accuracy_score\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install  pandas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "current_path = os.getcwd()\n",
    "current_path = os.path.dirname(current_path)\n",
    "print(current_path)\n",
    "#C:\\Users\\jonat\\Desktop\\capstone\\nfl2\\nfl_capstone\\data_mart\n",
    "dataset = current_path + '//data_mart//reporting_rb.csv'\n",
    "cities = current_path + '//data_mart//facts_cities_metrics.csv'\n",
    "college = current_path + '//data_mart//facts_college_metrics.csv'\n",
    "\n",
    "dimc_file = current_path + '//data_mart//dimensions_cities.csv'\n",
    "dimco_file = current_path + '//data_mart//dimensions_colleges.csv'\n",
    "dimp_file = current_path + '//data_mart//dimensions_players.csv'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(dataset)\n",
    "city_dim = pd.read_csv(dimc_file)\n",
    "college_dim = pd.read_csv(dimco_file)\n",
    "player_dim = pd.read_csv(dimp_file)\n",
    "\n",
    "dataset = pd.read_csv(dataset)\n",
    "college_df = pd.read_csv(college)\n",
    "city_df = pd.read_csv(cities)\n",
    "dataset.head()\n",
    "\n",
    "#https://stackoverflow.com/questions/9856683/using-pythons-os-path-how-do-i-go-up-one-directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset['football_spending']=dataset['coaches_salaries']=dataset['ticket_sales']=np.nan\n",
    "dataset['poverty_pct']=dataset['med_income']=dataset['ann_rain_inch']=dataset['ann_snow_inch']=dataset['min_jan']=dataset['min_feb']=dataset['min_mar']=dataset['min_apr']=dataset['min_may']=dataset['min_jun']=dataset['min_jul']=dataset['min_aug']=dataset['min_sep']=dataset['min_oct']=dataset['min_nov']=dataset['min_dec']=dataset['max_jan']=dataset['max_feb']=dataset['max_mar']=dataset['max_apr']=dataset['max_may']=dataset['max_jun']=dataset['max_jul']=dataset['max_aug']=dataset['max_sep']=dataset['max_oct']=dataset['max_nov']=dataset['max_dec']=np.nan\n",
    "for i in range(dataset.shape[0]):\n",
    "  lookup_val = dataset['fms_id'][i]\n",
    "  college_val = player_dim.loc[player_dim['fms_id'] == lookup_val]['fms_college_id'].values[0]\n",
    "  dataset.at[i,'football_spending'] = college_df.loc[college_df['fms_college_id'] == college_val]['football_spending'].values[0]\n",
    "  dataset.at[i,'coaches_salaries'] = college_df.loc[college_df['fms_college_id'] == college_val]['coaches_salaries'].values[0]\n",
    "  dataset.at[i,'ticket_sales'] = college_df.loc[college_df['fms_college_id'] == college_val]['ticket_sales'].values[0]\n",
    "  city_val = college_dim.loc[college_dim['fms_college_id'] == college_val]['fms_city_id'].values[0]\n",
    "  dataset.at[i,'poverty_pct'] = city_df.loc[city_df['fms_city_id'] == city_val]['poverty_pct'].values[0]\n",
    "  tmp = city_df.loc[city_df['fms_city_id'] == city_val]['med_income'].values[0]\n",
    "  if type(tmp) == str:\n",
    "    tmp = tmp.replace('$','').replace(',','')\n",
    "  dataset.at[i,'med_income'] = tmp\n",
    "  dataset.at[i,'ann_rain_inch'] = city_df.loc[city_df['fms_city_id'] == city_val]['ann_rain_inch'].values[0]\n",
    "  dataset.at[i,'ann_snow_inch'] = city_df.loc[city_df['fms_city_id'] == city_val]['ann_snow_inch'].values[0]\n",
    "  dataset.at[i,'min_jan'] = city_df.loc[city_df['fms_city_id'] == city_val]['min_jan'].values[0]\n",
    "  dataset.at[i,'min_feb'] = city_df.loc[city_df['fms_city_id'] == city_val]['min_feb'].values[0]\n",
    "  dataset.at[i,'min_mar'] = city_df.loc[city_df['fms_city_id'] == city_val]['min_mar'].values[0]\n",
    "  dataset.at[i,'min_apr'] = city_df.loc[city_df['fms_city_id'] == city_val]['min_apr'].values[0]\n",
    "  dataset.at[i,'min_may'] = city_df.loc[city_df['fms_city_id'] == city_val]['min_may'].values[0]\n",
    "  dataset.at[i,'min_jun'] = city_df.loc[city_df['fms_city_id'] == city_val]['min_jun'].values[0]\n",
    "  dataset.at[i,'min_jul'] = city_df.loc[city_df['fms_city_id'] == city_val]['min_jul'].values[0]\n",
    "  dataset.at[i,'min_aug'] = city_df.loc[city_df['fms_city_id'] == city_val]['min_aug'].values[0]\n",
    "  dataset.at[i,'min_sep'] = city_df.loc[city_df['fms_city_id'] == city_val]['min_sep'].values[0]\n",
    "  dataset.at[i,'min_oct'] = city_df.loc[city_df['fms_city_id'] == city_val]['min_oct'].values[0]\n",
    "  dataset.at[i,'min_nov'] = city_df.loc[city_df['fms_city_id'] == city_val]['min_nov'].values[0]\n",
    "  dataset.at[i,'min_dec'] = city_df.loc[city_df['fms_city_id'] == city_val]['min_dec'].values[0]\n",
    "  dataset.at[i,'max_jan'] = city_df.loc[city_df['fms_city_id'] == city_val]['max_jan'].values[0]\n",
    "  dataset.at[i,'max_feb'] = city_df.loc[city_df['fms_city_id'] == city_val]['max_feb'].values[0]\n",
    "  dataset.at[i,'max_mar'] = city_df.loc[city_df['fms_city_id'] == city_val]['max_mar'].values[0]\n",
    "  dataset.at[i,'max_apr'] = city_df.loc[city_df['fms_city_id'] == city_val]['max_apr'].values[0]\n",
    "  dataset.at[i,'max_may'] = city_df.loc[city_df['fms_city_id'] == city_val]['max_may'].values[0]\n",
    "  dataset.at[i,'max_jun'] = city_df.loc[city_df['fms_city_id'] == city_val]['max_jun'].values[0]\n",
    "  dataset.at[i,'max_jul'] = city_df.loc[city_df['fms_city_id'] == city_val]['max_jul'].values[0]\n",
    "  dataset.at[i,'max_aug'] = city_df.loc[city_df['fms_city_id'] == city_val]['max_aug'].values[0]\n",
    "  dataset.at[i,'max_sep'] = city_df.loc[city_df['fms_city_id'] == city_val]['max_sep'].values[0]\n",
    "  dataset.at[i,'max_oct'] = city_df.loc[city_df['fms_city_id'] == city_val]['max_oct'].values[0]\n",
    "  dataset.at[i,'max_nov'] = city_df.loc[city_df['fms_city_id'] == city_val]['max_nov'].values[0]\n",
    "  dataset.at[i,'max_dec'] = city_df.loc[city_df['fms_city_id'] == city_val]['max_dec'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in dataset.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine which columns have None values\n",
    "none_columns = []\n",
    "for x in dataset.columns:\n",
    "    if dataset[x].isnull().values.any() == True:\n",
    "        none_columns.append(x)\n",
    "print(none_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score_rescale(data_mean, data_std, z_score):\n",
    "    X = (z_score* data_std) + data_mean\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['max_madden'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deal with None Values\n",
    "none_dict = {'espn_id': 0,    \n",
    "    'selection_number': 400,\n",
    "    'position_rank': 400,\n",
    "    'position_group_rank': 400,\n",
    "    'section_rank': 400,\n",
    "    'drafting_team': 'No Team',\n",
    "    'home_city': 'No City',\n",
    "    'home_state': 'No State',\n",
    "    'home_country': 'USA',\n",
    "    'forty': dataset['forty'].mean(),\n",
    "    'vertical': dataset['vertical'].mean(), \n",
    "    'bench': dataset['bench'].mean(), \n",
    "    'broad': dataset['broad'].mean(),\n",
    "    'threecone': dataset['threecone'].mean(),\n",
    "    'shuttle': dataset['shuttle'].mean(),\n",
    "    'football_spending': dataset['shuttle'].mean(), \n",
    "    'coaches_salaries': dataset['shuttle'].mean(), \n",
    "    'ticket_sales': dataset['shuttle'].mean(), \n",
    "    'poverty_pct': dataset['shuttle'].mean(), \n",
    "    'med_income': dataset['shuttle'].mean(),\n",
    "    'max_madden': dataset['max_madden'].min() - 10,\n",
    "    'forty_zscore': dataset['forty_zscore'].mean(), \n",
    "    'vertical_zscore': dataset['vertical_zscore'].mean(), \n",
    "    'bench_zscore': dataset['bench_zscore'].mean(), \n",
    "    'broad_zscore': dataset['broad_zscore'].mean(), \n",
    "    'threecone_zscore': dataset['threecone_zscore'].mean(), \n",
    "    'shuttle_zscore': dataset['shuttle_zscore'].mean(), \n",
    "    \n",
    "    'max_madden_zscore': dataset['max_madden_zscore'].min() - 0.1,\n",
    "    'rushing_rec_td_pg_zscore': dataset['rushing_rec_td_pg_zscore'].min(), \n",
    "    'rushing_rec_yards_pg_zscore': dataset['rushing_rec_yards_pg_zscore'].min(), \n",
    "    'rushing_receptions_pg_zscore': dataset['rushing_receptions_pg_zscore'].min(), \n",
    "    'rushing_rush_att_pg_zscore': dataset['rushing_rush_att_pg_zscore'].min(), \n",
    "    'rushing_rush_td_pg_zscore': dataset['rushing_rush_td_pg_zscore'].min(), \n",
    "    'rushing_rush_yds_pg_zscore': dataset['rushing_rush_yds_pg_zscore'].min(), \n",
    "    'rushing_scrim_plays_pg_zscore': dataset['rushing_scrim_plays_pg_zscore'].min(), \n",
    "    'rushing_scrim_tds_pg_zscore': dataset['rushing_scrim_tds_pg_zscore'].min(), \n",
    "    'rushing_scrim_yds_pg_zscore': dataset['rushing_scrim_yds_pg_zscore'].min(),\n",
    "    'football_spending_zscore': dataset['football_spending_zscore'].min(), \n",
    "    'coaches_salaries_zscore':  dataset['coaches_salaries_zscore'].min(), \n",
    "    'ticket_sales_zscore':  dataset['ticket_sales_zscore'].min()}\n",
    "\n",
    "print(none_dict)\n",
    "\n",
    "for none_col in none_columns:\n",
    "    dataset[none_col] = dataset[none_col].fillna(none_dict[none_col])\n",
    "   \n",
    "\n",
    "#https://jakevdp.github.io/PythonDataScienceHandbook/03.04-missing-values.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create categories for Madden Scores\n",
    "def f(row):\n",
    "    if row['max_madden'] >= 90 : val = 90\n",
    "    elif row['max_madden'] < 90 and row['max_madden'] >= 80 : val = 80\n",
    "    elif row['max_madden'] < 80 and row['max_madden'] >= 70 : val = 70  \n",
    "    elif row['max_madden'] < 70 and row['max_madden'] >= 60 : val = 60\n",
    "    elif row['max_madden'] < 60 and row['max_madden'] >= 50 : val = 50\n",
    "    elif row['max_madden'] < 50 and row['max_madden'] >= 40 : val = 40\n",
    "    else: val = 40\n",
    "    return val\n",
    "dataset['madden_cat'] = dataset.apply(f, axis=1)\n",
    "\n",
    "\n",
    "def f_avg_min(row):\n",
    "    avg_min = (row['min_jan'] + row['min_feb'] + row['min_mar'] + row['min_apr'] + row['min_may'] + row['min_jun'] + row['min_jul'] + row['min_aug'] + row['min_sep'] + row['min_oct'] + row['min_nov'] + row['min_dec'])/12\n",
    "    return avg_min\n",
    "\n",
    "def f_avg_max(row):\n",
    "    avg_max = (row['max_jan'] + row['max_feb'] + row['max_mar'] + row['max_apr'] + row['max_may'] + row['max_jun'] + row['max_jul'] + row['max_aug'] + row['max_sep'] + row['max_oct'] + row['max_nov'] + row['max_dec'])/12\n",
    "    return avg_max\n",
    "\n",
    "dataset['avg_min'] = dataset.apply(f_avg_min, axis=1)\n",
    "\n",
    "\n",
    "dataset['avg_max'] = dataset.apply(f_avg_max, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#determine % of no madden scores wanted\n",
    "no_madden_percentage = .20\n",
    "\n",
    "no_madden_df = dataset.loc[dataset['madden_cat'] == 40]\n",
    "madden_df = dataset.loc[dataset['madden_cat'] != 40]\n",
    "\n",
    "print(no_madden_df.shape)\n",
    "print(madden_df.shape)\n",
    "\n",
    "current_no_madden_percentage = no_madden_df.shape[0] / dataset.shape[0] - no_madden_percentage\n",
    "print(current_no_madden_percentage)\n",
    "if current_no_madden_percentage > 0:\n",
    "    remove_num = int(current_no_madden_percentage * dataset.shape[0])\n",
    "    random_no_madden = np.random.choice(no_madden_df.index, remove_num)\n",
    "    no_madden_df = no_madden_df.drop(random_no_madden)\n",
    "\n",
    "print(no_madden_df.shape[0] / (no_madden_df.shape[0] + madden_df.shape[0]))\n",
    "dataset = madden_df.append(no_madden_df)\n",
    "dataset.head()\n",
    "dataset = shuffle(dataset)\n",
    "dataset.head()\n",
    "\n",
    "#https://stackoverflow.com/questions/28556942/pandas-remove-rows-at-random-without-shuffling-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns[30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Total Features\n",
    "\"\"\"['espn_id', 'full_name', 'first_name', 'last_name', 'position',\n",
    "       'position_group', 'section', 'college', 'draft_year',\n",
    "       'selection_number', 'position_rank', 'position_group_rank',\n",
    "       'section_rank', 'drafting_team', 'home_city', 'home_state',\n",
    "       'home_country', 'college_weight_pounds', 'college_height_inches',\n",
    "       'hw_ratio', 'forty', 'vertical', 'bench', 'broad', 'threecone',\n",
    "       'shuttle', 'rushing_games', 'rushing_rec_td', 'rushing_rec_yards',\n",
    "       'rushing_receptions', 'rushing_rush_att', 'rushing_rush_td',\n",
    "       'rushing_rush_yds', 'rushing_scrim_plays', 'rushing_scrim_tds',\n",
    "       'rushing_scrim_yds', 'rushing_seasons', 'college_weight_pounds_zscore',\n",
    "       'college_height_inches_zscore', 'hw_ratio_zscore', 'forty_zscore',\n",
    "       'vertical_zscore', 'bench_zscore', 'broad_zscore', 'threecone_zscore',\n",
    "       'shuttle_zscore', 'rushing_games_zscore', 'rushing_rec_td_zscore',\n",
    "       'rushing_rec_yards_zscore', 'rushing_receptions_zscore',\n",
    "       'rushing_rush_att_zscore', 'rushing_rush_td_zscore',\n",
    "       'rushing_rush_yds_zscore', 'rushing_scrim_plays_zscore',\n",
    "       'rushing_scrim_tds_zscore', 'rushing_scrim_yds_zscore',\n",
    "       'rushing_seasons_zscore', 'max_madden_zscore',\n",
    "       'rushing_rec_td_pg_zscore', 'rushing_rec_yards_pg_zscore',\n",
    "       'rushing_receptions_pg_zscore', 'rushing_rush_att_pg_zscore',\n",
    "       'rushing_rush_td_pg_zscore', 'rushing_rush_yds_pg_zscore',\n",
    "       'rushing_scrim_plays_pg_zscore', 'rushing_scrim_tds_pg_zscore',\n",
    "       'rushing_scrim_yds_pg_zscore', 'football_spending_zscore',\n",
    "       'coaches_salaries_zscore', 'ticket_sales_zscore', 'max_madden',\n",
    "       'football_spending', 'coaches_salaries', 'ticket_sales', 'poverty_pct',\n",
    "       'med_income', 'ann_rain_inch', 'ann_snow_inch', 'min_jan', 'min_feb',\n",
    "       'min_mar', 'min_apr', 'min_may', 'min_jun', 'min_jul', 'min_aug',\n",
    "       'min_sep', 'min_oct', 'min_nov', 'min_dec', 'max_jan', 'max_feb',\n",
    "       'max_mar', 'max_apr', 'max_may', 'max_jun', 'max_jul', 'max_aug',\n",
    "       'max_sep', 'max_oct', 'max_nov', 'max_dec', 'avg_min',\n",
    "       'avg_max', 'madden_cat']\"\"\"\n",
    "\n",
    "# 'college_weight_pounds', 'college_height_inches'\n",
    "\n",
    "\n",
    "features = ['college_weight_pounds', 'college_height_inches', 'forty', 'vertical', 'bench', 'broad', 'threecone',\n",
    "       'shuttle', 'rushing_games', 'rushing_rec_td', 'rushing_rec_yards',\n",
    "       'rushing_receptions', 'rushing_rush_att', 'rushing_rush_td',\n",
    "       'rushing_rush_yds', 'rushing_scrim_plays', 'rushing_scrim_tds',\n",
    "       'rushing_scrim_yds', 'rushing_seasons', 'football_spending', 'coaches_salaries', 'ticket_sales', 'poverty_pct',\n",
    "       'med_income', 'ann_rain_inch', 'ann_snow_inch']\n",
    "\n",
    "z_features = ['hw_ratio_zscore', 'forty_zscore', 'vertical_zscore', 'bench_zscore',\n",
    "       'broad_zscore', 'threecone_zscore', 'shuttle_zscore',\n",
    "       'rushing_games_zscore', 'rushing_rec_td_zscore',\n",
    "       'rushing_rec_yards_zscore', 'rushing_receptions_zscore',\n",
    "       'rushing_rush_att_zscore', 'rushing_rush_td_zscore',\n",
    "       'rushing_rush_yds_zscore', 'rushing_scrim_plays_zscore',\n",
    "       'rushing_scrim_tds_zscore', 'rushing_scrim_yds_zscore',\n",
    "       'rushing_seasons_zscore','football_spending_zscore',\n",
    "       'coaches_salaries_zscore', 'ticket_sales_zscore']\n",
    "\n",
    "z_features_per_game = ['hw_ratio_zscore', 'forty_zscore', 'vertical_zscore', 'bench_zscore',\n",
    "       'broad_zscore', 'threecone_zscore', 'shuttle_zscore',\n",
    "       'rushing_rec_td_pg_zscore', 'rushing_rec_yards_pg_zscore',\n",
    "       'rushing_receptions_pg_zscore', 'rushing_rush_att_pg_zscore',\n",
    "       'rushing_rush_td_pg_zscore', 'rushing_rush_yds_pg_zscore',\n",
    "       'rushing_scrim_plays_pg_zscore', 'rushing_scrim_tds_pg_zscore',\n",
    "       'rushing_scrim_yds_pg_zscore', 'football_spending_zscore',\n",
    "       'coaches_salaries_zscore', 'ticket_sales_zscore']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "limit_features = ['rushing_rush_yds_zscore', 'rushing_scrim_yds_zscore', 'broad_zscore', 'rushing_receptions_zscore', \n",
    "'rushing_rush_att_zscore', 'rushing_scrim_plays_zscore', 'rushing_seasons_zscore', 'vertical_zscore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def game_avg(row):\n",
    "    stats_list = ['rushing_rec_td', 'rushing_rec_yards',\n",
    "       'rushing_receptions', 'rushing_rush_att', 'rushing_rush_td', 'rushing_rush_yds', 'rushing_scrim_plays', 'rushing_scrim_tds',\n",
    "       'rushing_scrim_yds']\n",
    "    if row['rushing_games'] == 0:\n",
    "        pass\n",
    "    else:\n",
    "        for stat in stats_list:\n",
    "            row[stat] = row[stat]/row['rushing_games']\n",
    "    return row\n",
    "\n",
    "\n",
    "#use game averages?\n",
    "game_averages = 'Y'\n",
    "if game_averages == 'Y':\n",
    "    dataset = dataset.apply(game_avg, axis=1)\n",
    "else: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select year to hold out\n",
    "holdout_year = 2015\n",
    "#pick features from above\n",
    "features_list = features\n",
    "\n",
    "\n",
    "\n",
    "#z_score features\n",
    "#dataset['max_madden_zscore'] = stats.zscore(dataset['max_madden'].values)\n",
    "\n",
    "for col in dataset[features_list].columns:\n",
    "    dataset[col] = stats.zscore(dataset[col].values)\n",
    "\n",
    "\n",
    "#prediction feature\n",
    "#prediction_feature = 'max_madden'\n",
    "#prediction_feature = 'max_madden_zscore'\n",
    "prediction_feature = 'madden_cat'\n",
    "features_list.append(prediction_feature)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#create a train and test df based on the hold out year\n",
    "test_df = dataset.loc[dataset['draft_year'] == holdout_year]\n",
    "train_df = dataset.loc[dataset['draft_year'] != holdout_year]\n",
    "\n",
    "#shuffle the dataset\n",
    "test_df = shuffle(test_df)\n",
    "train_df = shuffle(train_df)\n",
    "\n",
    "#create a copy of the dataset with that feature set\n",
    "test_df_feat = test_df[features_list].copy()\n",
    "train_df_feat = train_df[features_list].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = train_df_feat[:].drop([prediction_feature], axis =1), train_df_feat.pop(prediction_feature)\n",
    "X_validation, Y_validation = test_df_feat[:].drop([prediction_feature], axis =1), test_df_feat.pop(prediction_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#quick check that the original dataset and copied dataset have the same score\n",
    "print(Y_train[113])\n",
    "dataset[prediction_feature][113]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograms for some interesting measurements\n",
    "X_train.hist()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = test_df[['full_name', prediction_feature, 'position_group_rank']].copy()\n",
    "print(result_df)\n",
    "def result_df_viz(df, predictions, model_name):\n",
    "    \n",
    "    df[model_name] = predictions\n",
    "    #return result_df.sort_values(by=['max_madden_pred'], ascending=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   # Plot feature importance\n",
    "def plot_feat_import(coef, model_title):\n",
    "    feature_coef = pd.Series(index=X_train.columns, data=coef)\n",
    "    print('{} model picked {} out of {} features'.format(model_title, str(sum(feature_coef != 0)), str(X_train.shape[1])))\n",
    "    top_bottom_10 = pd.concat([feature_coef.sort_values().head(10), feature_coef.sort_values().tail(10)])\n",
    "    top_bottom_10.plot(kind='barh', title='Feature importance (Top and bottom 10) - {} model'.format(model_title))\n",
    "    #from W207 project (Fleishman, Hilton, Niu)\n",
    "    \n",
    "# Plot predictions\n",
    "def plot_it(y_train, y_valid, model_title):\n",
    "    plt.scatter(y_train, train_labels, c = \"blue\", alpha=0.6, marker = \"o\", label = \"Training data\")\n",
    "    plt.scatter(y_valid, dev_labels, c = \"green\", alpha=0.6, marker = \"o\", label = \"Validation data\")\n",
    "    plt.title(model_title)\n",
    "    plt.xlabel(\"Predicted values\")\n",
    "    plt.ylabel(\"Real values\")\n",
    "    plt.legend(loc = \"upper left\")\n",
    "    plt.plot([10.5, 13.5], [10.5, 13.5], c = \"red\")\n",
    "    plt.show()\n",
    "    \n",
    "def print_results(true_val, predict_val):\n",
    "    print('Accuracy:  ' + str(accuracy_score(true_val, predict_val)))\n",
    "    print('R2 : ' + str(r2_score(true_val, predict_val)))\n",
    "    print('MSE : ' + str(mean_squared_error(true_val, predict_val)))\n",
    "    \n",
    "\n",
    "def plot_confusion(mat, model):\n",
    "    \n",
    "    array = mat\n",
    "    df_cm = pd.DataFrame(array, index = [i for i in class_names],\n",
    "                      columns = [i for i in class_names])\n",
    "    plt.figure(figsize = (10,7))\n",
    "    plt.title(model)\n",
    "    sn.heatmap(df_cm, annot=True, cmap=\"Blues\")\n",
    "\n",
    "\n",
    "#https://stackoverflow.com/questions/35572000/how-can-i-plot-a-confusion-matrix\n",
    "    \n",
    "    \n",
    "class_names = [40, 50, 60, 70, 80, 90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adaboost\n",
    "adaboostregressor = AdaBoostRegressor(DecisionTreeRegressor(criterion='mse'), n_estimators=100, loss='linear', learning_rate=1, random_state=1)\n",
    "adaboostregressor.fit(X_train, Y_train)\n",
    "madden_predict = adaboostregressor.predict(X_validation)\n",
    "print_results(Y_validation, madden_predict)\n",
    "plot_feat_import(adaboostregressor.feature_importances_, 'AdaBoostRegressor')\n",
    "mat = confusion_matrix(Y_validation, madden_predict, labels = class_names)\n",
    "plot_confusion(mat, 'Adaboost')\n",
    "result_df_viz(result_df, madden_predict, 'AdaBoost')\n",
    "#plot_confusion_matrix(adaboostregressor, X_validation, Y_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = adaboostregressor\n",
    "kfold = StratifiedKFold(n_splits=30, random_state=1, shuffle=True)\n",
    "cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n",
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression:\n",
    "clf = LogisticRegression(random_state=1).fit(X_train, Y_train)\n",
    "madden_predict = clf.predict(X_validation)\n",
    "print_results(Y_validation, madden_predict)\n",
    "mat = confusion_matrix(Y_validation, madden_predict, labels = class_names)\n",
    "plot_confusion(mat, 'Log Regression')\n",
    "result_df_viz(result_df, madden_predict, 'Log_Regression')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lasso:\n",
    "alpha = 0.1\n",
    "lasso_model = Lasso(alpha=alpha).fit(X_train, Y_train)\n",
    "madden_predict = lasso_model.predict(X_validation)\n",
    "\n",
    "madden_predict = np.around(madden_predict, decimals = 0)\n",
    "print_results(Y_validation, madden_predict)\n",
    "plot_feat_import(lasso_model.coef_, 'Lasso')  \n",
    "#plot_it()\n",
    "print('----------')\n",
    "result_df_viz(result_df, madden_predict, 'Lasso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lassocv:\n",
    "\n",
    "lasso_modelcv = LassoCV(cv=5, random_state=0).fit(X_train, Y_train)\n",
    "madden_predict = lasso_modelcv.predict(X_validation)\n",
    "madden_predict = np.around(madden_predict, decimals = 0)\n",
    "print_results(Y_validation, madden_predict)\n",
    "print('LassoCV Model')\n",
    "plot_feat_import(lasso_modelcv.coef_, 'Lassocv') \n",
    "print('----------')\n",
    "result_df_viz(result_df, madden_predict, 'LassoCV')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RidgeCV:\n",
    "\n",
    "ridge_model = RidgeCV(cv=5).fit(X_train, Y_train)\n",
    "madden_predict = ridge_model.predict(X_validation)\n",
    "madden_predict = np.around(madden_predict, decimals = 0)\n",
    "print_results(Y_validation, madden_predict)\n",
    "\n",
    "plot_feat_import(ridge_model.coef_, 'RidgeCV')\n",
    "print('----------')\n",
    "result_df_viz(result_df, madden_predict, 'RidgeCV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ElasticNetCV:\n",
    "\n",
    "elasticnetcv_model = ElasticNetCV(cv=5, random_state=0).fit(X_train, Y_train)\n",
    "madden_predict = elasticnetcv_model.predict(X_validation)\n",
    "madden_predict = np.around(madden_predict, decimals = 0)\n",
    "print_results(Y_validation, madden_predict)\n",
    "plot_feat_import(elasticnetcv_model.coef_, 'ElasticNetCV')\n",
    "result_df_viz(result_df, madden_predict, 'ElasticNetCV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Regressor\n",
    "decisiontreeregrssor = DecisionTreeRegressor()\n",
    "decisiontreeregrssor.fit(X_train, Y_train)\n",
    "madden_predict = decisiontreeregrssor.predict(X_validation)\n",
    "print_results(Y_validation, madden_predict)\n",
    "plot_feat_import(decisiontreeregrssor.feature_importances_, 'Decision Tree Regressor')\n",
    "result_df_viz(result_df, madden_predict, 'Decision_Tree_Reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "from sklearn import tree\n",
    "decisiontree = DecisionTreeClassifier(max_depth = 100)\n",
    "decisiontree.fit(X_train, Y_train)\n",
    "madden_predict = decisiontree.predict(X_validation)\n",
    "print('Accuracy:  ' + str(accuracy_score(Y_validation, madden_predict)))\n",
    "print('R2 : ' + str(r2_score(Y_validation, madden_predict)))\n",
    "print('MSE : ' + str(mean_squared_error(Y_validation, madden_predict)))\n",
    "plot_feat_import(decisiontree.feature_importances_, 'Decision Tree Classifier')\n",
    "print(confusion_matrix(Y_validation, madden_predict))\n",
    "plot_confusion_matrix(decisiontree, X_validation, Y_validation, labels = class_names)\n",
    "result_df_viz(result_df, madden_predict, 'Decision_Tree_Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extra Tree\n",
    "\n",
    "\n",
    "from sklearn import tree\n",
    "extradecisiontree = ExtraTreesClassifier(max_depth = 300)\n",
    "extradecisiontree.fit(X_train, Y_train)\n",
    "madden_predict = extradecisiontree.predict(X_validation)\n",
    "print('Accuracy:  ' + str(accuracy_score(Y_validation, madden_predict)))\n",
    "print('R2 : ' + str(r2_score(Y_validation, madden_predict)))\n",
    "print('MSE : ' + str(mean_squared_error(Y_validation, madden_predict)))\n",
    "plot_feat_import(extradecisiontree.feature_importances_, 'Extra Tree Classifier')\n",
    "result_df_viz(result_df, madden_predict, 'Extra_Tree')\n",
    "print(confusion_matrix(Y_validation, madden_predict))\n",
    "plot_confusion_matrix(extradecisiontree, X_validation, Y_validation, labels=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adaboost\n",
    "adaboostclassifier = AdaBoostClassifier(DecisionTreeClassifier(), n_estimators=500)\n",
    "adaboostclassifier.fit(X_train, Y_train)\n",
    "madden_predict = adaboostclassifier.predict(X_validation)\n",
    "print('Accuracy:  ' + str(accuracy_score(Y_validation, madden_predict)))\n",
    "print('R2 : ' + str(r2_score(Y_validation, madden_predict)))\n",
    "print('MSE : ' + str(mean_squared_error(Y_validation, madden_predict)))\n",
    "plot_feat_import(adaboostclassifier.feature_importances_, 'AdaBoostClassifier')\n",
    "\n",
    "plot_confusion_matrix(adaboostclassifier, X_validation, Y_validation, labels = class_names)\n",
    "result_df_viz(result_df, madden_predict, 'AdaBoost_Class')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "svmclassifier = SVC(gamma='auto')\n",
    "svmclassifier.fit(X_train, Y_train)\n",
    "madden_predict = svmclassifier.predict(X_validation)\n",
    "print('Accuracy:  ' + str(accuracy_score(Y_validation, madden_predict)))\n",
    "print('R2 : ' + str(r2_score(Y_validation, madden_predict)))\n",
    "print('MSE : ' + str(mean_squared_error(Y_validation, madden_predict)))\n",
    "#plot_feat_import(svmclassifier.feature_importances_, 'SVC')\n",
    "plot_confusion_matrix(svmclassifier, X_validation, Y_validation, labels = class_names)\n",
    "result_df_viz(result_df, madden_predict, 'SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForest\n",
    "rfclassifier = RandomForestClassifier()\n",
    "rfclassifier.fit(X_train, Y_train)\n",
    "madden_predict = rfclassifier.predict(X_validation)\n",
    "print('Accuracy:  ' + str(accuracy_score(Y_validation, madden_predict)))\n",
    "print('R2 : ' + str(r2_score(Y_validation, madden_predict)))\n",
    "print('MSE : ' + str(mean_squared_error(Y_validation, madden_predict)))\n",
    "plot_feat_import(rfclassifier.feature_importances_, 'Random Forest')\n",
    "result_df_viz(result_df, madden_predict, 'RF_Class')\n",
    "plot_confusion_matrix(rfclassifier, X_validation, Y_validation, labels = class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA with Linear Regression\n",
    "pca = PCA(n_components=5)\n",
    "pca_x = pca.fit_transform(X_train)\n",
    "pca_validation = pca.transform(X_validation)\n",
    "\n",
    "log_pca = LogisticRegression(random_state=0).fit(pca_x, Y_train)\n",
    "madden_predict = log_pca.predict(pca_validation)\n",
    "print('Accuracy:  ' + str(accuracy_score(Y_validation, madden_predict)))\n",
    "print('R2 : ' + str(r2_score(Y_validation, madden_predict)))\n",
    "print('MSE : ' + str(mean_squared_error(Y_validation, madden_predict)))\n",
    "#print(log_pca.coef_.shape)\n",
    "#plot_feat_import(log_pca.coef_, 'PCA with Log Regression')\n",
    "result_df_viz(result_df, madden_predict, 'Log_PCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Booster Regressor\n",
    "import numpy as np\n",
    "gradientboostingregressor = GradientBoostingRegressor(random_state=0)\n",
    "gradientboostingregressor.fit(X_train, Y_train)\n",
    "madden_predict = gradientboostingregressor.predict(X_validation)\n",
    "madden_predict = np.around(madden_predict, decimals = 0)\n",
    "print('Accuracy:  ' + str(accuracy_score(Y_validation, madden_predict)))\n",
    "print('R2 : ' + str(r2_score(Y_validation, madden_predict)))\n",
    "print('MSE : ' + str(mean_squared_error(Y_validation, madden_predict)))\n",
    "plot_feat_import(gradientboostingregressor.feature_importances_, 'Gradient Booster Regressor')\n",
    "result_df_viz(result_df, madden_predict, 'GB_Regressor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import rankdata\n",
    "print(result_df.columns[3:])\n",
    "rank_df = result_df[result_df.columns[3:]]\n",
    "#for col in rank_df.columns:\n",
    "#    rank_df[col] = rankdata(rank_df[col].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank(row):\n",
    "    print()\n",
    "    return row.sum()/len(row)\n",
    "result_df['rank'] = rank_df.apply(rank, axis=1)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def rank(row):\n",
    "#    print()\n",
    "#    return row.sum()/len(row)\n",
    "#result_df['rank'] = rankdata(rank_df.apply(rank, axis=1))\n",
    "\n",
    "ordered_df = result_df[['full_name', 'AdaBoost', prediction_feature, 'position_group_rank']].sort_values(by=['AdaBoost'], ascending=False)\n",
    "ordered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_df.to_csv('rank_of_picks.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eclf = VotingClassifier(estimators=[('svc', svmclassifier), ('extratrees', extradecisiontree), ('rf', rfclassifier), ('logpca', log_pca)],voting='hard')\n",
    "\n",
    "\n",
    "for clf, label in zip([svmclassifier, extradecisiontree, rfclassifier, log_pca, eclf], ['SVC', 'Extra Trees', 'Random Forest', 'Log_pca', 'Ensemble']): \n",
    "    scores = cross_val_score(clf, value_data, label_data, scoring='accuracy', cv=5)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n",
    "    \n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot Check Algorithms\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "#models.append(('LASSO', Lasso(alpha=0.1)))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('ABC', AdaBoostClassifier()))\n",
    "models.append(('GBC', GradientBoostingClassifier(n_estimators=200)))\n",
    "models.append(('RFC', RandomForestClassifier()))\n",
    "models.append(('GNB', GaussianNB()))\n",
    "models.append(('SVM', SVC(gamma='auto')))\n",
    "models.append(('ETC', ExtraTreesClassifier()))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "    cv_results = cross_val_score(model, value_data, label_data, cv=kfold, scoring='accuracy')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "pyplot.boxplot(results, labels=names)\n",
    "pyplot.title('Algorithm Comparison')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
