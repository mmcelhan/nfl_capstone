{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "dlopen(/Users/andrewmorris/opt/anaconda3/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n  Referenced from: /Users/andrewmorris/opt/anaconda3/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so\n  Reason: image not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-04f2005b50bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLGBMRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m from .callback import (early_stopping, print_evaluation, record_evaluation,\n\u001b[1;32m     10\u001b[0m                        reset_parameter)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0m_LIB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mlib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/ctypes/__init__.py\u001b[0m in \u001b[0;36mLoadLibrary\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dlltype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0mcdll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLibraryLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: dlopen(/Users/andrewmorris/opt/anaconda3/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n  Referenced from: /Users/andrewmorris/opt/anaconda3/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so\n  Reason: image not found"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import os\n",
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import plot_confusion_matrix, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas_profiling\n",
    "\n",
    "\n",
    "from scipy.stats import skew, norm\n",
    "from scipy import stats\n",
    "from scipy.special import boxcox1p\n",
    "from sklearn.preprocessing import LabelEncoder, PolynomialFeatures, RobustScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import ElasticNetCV, ElasticNet, LinearRegression, Lasso, LassoCV, Ridge, RidgeCV, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor, AdaBoostClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_squared_log_error, classification_report, accuracy_score\n",
    "from math import sqrt\n",
    "\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "#from lightgbm import LGBMRegressor\n",
    "#import lightgbm as lgb\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "current_path = os.getcwd()\n",
    "current_path = os.path.dirname(current_path)\n",
    "print(current_path)\n",
    "#C:\\Users\\jonat\\Desktop\\capstone\\nfl2\\nfl_capstone\\data_mart\n",
    "dataset = current_path + '//data_mart//reporting_rb.csv'\n",
    "cities = current_path + '//data_mart//facts_cities_metrics.csv'\n",
    "college = current_path + '//data_mart//facts_college_metrics.csv'\n",
    "\n",
    "dimc_file = current_path + '//data_mart//dimensions_cities.csv'\n",
    "dimco_file = current_path + '//data_mart//dimensions_colleges.csv'\n",
    "dimp_file = current_path + '//data_mart//dimensions_players.csv'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(dataset)\n",
    "city_dim = pd.read_csv(dimc_file)\n",
    "college_dim = pd.read_csv(dimco_file)\n",
    "player_dim = pd.read_csv(dimp_file)\n",
    "\n",
    "dataset = pd.read_csv(dataset)\n",
    "college_df = pd.read_csv(college)\n",
    "city_df = pd.read_csv(cities)\n",
    "\n",
    "\n",
    "#https://stackoverflow.com/questions/9856683/using-pythons-os-path-how-do-i-go-up-one-directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in dataset.columns:\n",
    "    print(x)\n",
    "    #print(dataset[x].describe)\n",
    "    #print('-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine which columns have None values\n",
    "none_columns = []\n",
    "for x in dataset.columns:\n",
    "    if dataset[x].isnull().values.any() == True:\n",
    "        none_columns.append(x)\n",
    "print(none_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deal with None Values\n",
    "none_dict = {'espn_id': 0, \n",
    "    'conference':  'non_power_five',\n",
    "    'selection_number': 400,\n",
    "    'position_rank': 400,\n",
    "    'position_group_rank': 400,\n",
    "    'section_rank': 400,\n",
    "    'drafting_team': 'No Team',\n",
    "    'home_city': 'No City',\n",
    "    'home_state': 'No State',\n",
    "    'home_country': 'USA',\n",
    "    'forty': dataset['forty'].mean(),\n",
    "    'vertical': dataset['vertical'].mean(), \n",
    "    'bench': dataset['bench'].mean(), \n",
    "    'broad': dataset['broad'].mean(),\n",
    "    'threecone': dataset['threecone'].mean(),\n",
    "    'shuttle': dataset['shuttle'].mean(),\n",
    "    'rb_football_spending': dataset['shuttle'].mean(), \n",
    "    'rb_coaches_salaries': dataset['shuttle'].mean(), \n",
    "    'rb_ticket_sales': dataset['shuttle'].mean(), \n",
    "    'rb_poverty_pct': dataset['shuttle'].mean(), \n",
    "    'rb_med_income': dataset['shuttle'].mean(),\n",
    "    'max_madden': dataset['max_madden'].min() - 10,\n",
    "    'rb_forty_zscore': 0, \n",
    "    'rb_vertical_zscore': 0, \n",
    "    'rb_bench_zscore': 0, \n",
    "    'rb_broad_zscore': 0, \n",
    "    'rb_threecone_zscore': 0, \n",
    "    'rb_shuttle_zscore': 0, \n",
    "    \n",
    "    'rb_max_madden_zscore': dataset['rb_max_madden_zscore'].min() - 0.1,\n",
    "    'rb_rushing_rec_td_pg_zscore': 0, \n",
    "    'rb_rushing_rec_yards_pg_zscore': 0, \n",
    "    'rb_rushing_receptions_pg_zscore': 0, \n",
    "    'rb_rushing_rush_att_pg_zscore': 0, \n",
    "    'rb_rushing_rush_td_pg_zscore': 0, \n",
    "    'rb_rushing_rush_yds_pg_zscore': 0, \n",
    "    'rb_rushing_scrim_plays_pg_zscore': 0, \n",
    "    'rb_rushing_scrim_tds_pg_zscore': 0, \n",
    "    'rb_rushing_scrim_yds_pg_zscore': 0,\n",
    "    'rb_rushing_rush_td_pg_cf_scaled_zscore': 0, \n",
    "    'rb_rushing_rush_yds_pg_cf_scaled_zscore': 0, \n",
    "    'rb_rushing_scrim_plays_pg_cf_scaled_zscore': 0, \n",
    "    'rb_rushing_scrim_tds_pg_cf_scaled_zscore': 0,\n",
    "    'rb_rushing_scrim_yds_pg_cf_scaled_zscore': 0,\n",
    "             \n",
    "    'rb_football_spending_zscore': 0, \n",
    "    'rb_coaches_salaries_zscore':  0, \n",
    "    'rb_ticket_sales_zscore':  0}\n",
    "\n",
    "print(none_dict)\n",
    "\n",
    "for none_col in none_columns:\n",
    "    dataset[none_col] = dataset[none_col].fillna(none_dict[none_col])\n",
    "   \n",
    "\n",
    "#https://jakevdp.github.io/PythonDataScienceHandbook/03.04-missing-values.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create categories for Madden Scores\n",
    "def f(row):\n",
    "    if row['max_madden'] >= 90 : val = 90\n",
    "    elif row['max_madden'] < 90 and row['max_madden'] >= 80 : val = 80\n",
    "    elif row['max_madden'] < 80 and row['max_madden'] >= 70 : val = 70  \n",
    "    elif row['max_madden'] < 70 and row['max_madden'] >= 60 : val = 60\n",
    "    elif row['max_madden'] < 60 and row['max_madden'] >= 50 : val = 50\n",
    "    elif row['max_madden'] < 50 and row['max_madden'] >= 40 : val = 40\n",
    "    else: val = 40\n",
    "    return val\n",
    "dataset['madden_cat'] = dataset.apply(f, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def f_avg_min(row):\n",
    "    avg_min = (row['min_jan'] + row['min_feb'] + row['min_mar'] + row['min_apr'] + row['min_may'] + row['min_jun'] + row['min_jul'] + row['min_aug'] + row['min_sep'] + row['min_oct'] + row['min_nov'] + row['min_dec'])/12\n",
    "    return avg_min\n",
    "\n",
    "def f_avg_max(row):\n",
    "    avg_max = (row['max_jan'] + row['max_feb'] + row['max_mar'] + row['max_apr'] + row['max_may'] + row['max_jun'] + row['max_jul'] + row['max_aug'] + row['max_sep'] + row['max_oct'] + row['max_nov'] + row['max_dec'])/12\n",
    "    return avg_max\n",
    "\n",
    "dataset['avg_min'] = dataset.apply(f_avg_min, axis=1)\n",
    "\n",
    "\n",
    "dataset['avg_max'] = dataset.apply(f_avg_max, axis=1)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####REMOVE ALL NO MADDEN SCORES thru 2014 and keep all NO MADDEN SCORES 2015 forward\n",
    "#determine % of no madden scores wanted\n",
    "no_madden_percentage = .25\n",
    "\n",
    "no_madden_df = dataset.loc[dataset['madden_cat'] == 40]\n",
    "madden_df = dataset.loc[dataset['madden_cat'] != 40]\n",
    "\n",
    "print(no_madden_df.shape)\n",
    "print(madden_df.shape)\n",
    "\n",
    "current_no_madden_percentage = no_madden_df.shape[0] / dataset.shape[0] - no_madden_percentage\n",
    "print(current_no_madden_percentage)\n",
    "\n",
    "for x in set(dataset['draft_year'].values):\n",
    "    if x in [2015, 2016, 2017, 2018, 2019]:\n",
    "        year_df = no_madden_df.loc[dataset['draft_year'] == x]\n",
    "        madden_df = madden_df.append(year_df)\n",
    "\n",
    "\n",
    "dataset = madden_df\n",
    "print(dataset.shape)\n",
    "dataset.head()\n",
    "dataset = shuffle(dataset)\n",
    "dataset.head()\n",
    "\n",
    "#https://stackoverflow.com/questions/28556942/pandas-remove-rows-at-random-without-shuffling-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns[20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Total Features\n",
    "\"\"\"['espn_id', 'fms_college_id', 'fms_city_id', 'full_name',\n",
    "       'first_name', 'last_name', 'position', 'position_group', 'section',\n",
    "       'college', 'conference', 'draft_year', 'selection_number',\n",
    "       'position_rank', 'position_group_rank', 'section_rank', 'drafting_team',\n",
    "       'home_city', 'home_state',\n",
    "       'home_country', 'college_weight_pounds', 'college_height_inches',\n",
    "       'hw_ratio', 'forty', 'vertical', 'bench', 'broad', 'threecone',\n",
    "       'shuttle', 'rushing_games', 'rushing_rec_td', 'rushing_rec_yards',\n",
    "       'rushing_receptions', 'rushing_rush_att', 'rushing_rush_td',\n",
    "       'rushing_rush_yds', 'rushing_scrim_plays', 'rushing_scrim_tds',\n",
    "       'rushing_scrim_yds', 'rushing_seasons',\n",
    "       'rb_college_weight_pounds_zscore', 'rb_college_height_inches_zscore',\n",
    "       'rb_hw_ratio_zscore', 'rb_forty_zscore', 'rb_vertical_zscore',\n",
    "       'rb_bench_zscore', 'rb_broad_zscore', 'rb_threecone_zscore',\n",
    "       'rb_shuttle_zscore', 'rb_rushing_games_zscore',\n",
    "       'rb_rushing_rec_td_zscore', 'rb_rushing_rec_yards_zscore',\n",
    "       'rb_rushing_receptions_zscore', 'rb_rushing_rush_att_zscore',\n",
    "       'rb_rushing_rush_td_zscore', 'rb_rushing_rush_yds_zscore',\n",
    "       'rb_rushing_scrim_plays_zscore', 'rb_rushing_scrim_tds_zscore',\n",
    "       'rb_rushing_scrim_yds_zscore', 'rb_rushing_seasons_zscore',\n",
    "       'rb_max_madden_zscore', 'rb_rushing_rec_td_pg_zscore',\n",
    "       'rb_rushing_rec_yards_pg_zscore', 'rb_rushing_receptions_pg_zscore',\n",
    "       'rb_rushing_rush_att_pg_zscore', 'rb_rushing_rush_td_pg_zscore',\n",
    "       'rb_rushing_rush_yds_pg_zscore', 'rb_rushing_scrim_plays_pg_zscore',\n",
    "       'rb_rushing_scrim_tds_pg_zscore', 'rb_rushing_scrim_yds_pg_zscore',\n",
    "       'rb_football_spending_zscore', 'rb_coaches_salaries_zscore',\n",
    "       'rb_ticket_sales_zscore', 'rb_ann_rain_inch_zscore',\n",
    "       'rb_ann_snow_inch_zscore', 'rb_min_jan_zscore', 'rb_min_feb_zscore',\n",
    "       'rb_min_mar_zscore', 'rb_min_apr_zscore', 'rb_min_may_zscore',\n",
    "       'rb_min_jun_zscore', 'rb_min_jul_zscore', 'rb_min_aug_zscore',\n",
    "       'rb_min_sep_zscore', 'rb_min_oct_zscore', 'rb_min_nov_zscore',\n",
    "       'rb_min_dec_zscore', 'rb_max_jan_zscore', 'rb_max_feb_zscore',\n",
    "       'rb_max_mar_zscore', 'rb_max_apr_zscore', 'rb_max_may_zscore',\n",
    "       'rb_max_jun_zscore', 'rb_max_jul_zscore', 'rb_max_aug_zscore',\n",
    "       'rb_rushing_rush_td_pg_cf_scaled_zscore',\n",
    "       'rb_rushing_rush_yds_pg_cf_scaled_zscore',\n",
    "       'rb_rushing_scrim_plays_pg_cf_scaled_zscore',\n",
    "       'rb_rushing_scrim_tds_pg_cf_scaled_zscore',\n",
    "       'rb_rushing_scrim_yds_pg_cf_scaled_zscore', 'max_madden']\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 'college_weight_pounds', 'college_height_inches'\n",
    "\n",
    "\n",
    "features = ['college_weight_pounds', 'college_height_inches', 'forty', 'vertical', 'bench', 'broad', 'threecone',\n",
    "       'shuttle', 'rushing_games', 'rushing_rec_td', 'rushing_rec_yards',\n",
    "       'rushing_receptions', 'rushing_rush_att', 'rushing_rush_td',\n",
    "       'rushing_rush_yds', 'rushing_scrim_plays', 'rushing_scrim_tds',\n",
    "       'rushing_scrim_yds', 'rushing_seasons', 'ann_rain_inch', 'ann_snow_inch',\n",
    "       'min_jan', 'min_feb',\n",
    "       'min_mar', 'min_apr', 'min_may', 'min_jun', 'min_jul', 'min_aug',\n",
    "       'min_sep', 'min_oct', 'min_nov', 'min_dec', 'max_jan', 'max_feb',\n",
    "       'max_mar', 'max_apr', 'max_may', 'max_jun', 'max_jul', 'max_aug',\n",
    "       'max_sep', 'max_oct', 'max_nov', 'max_dec']\n",
    "\n",
    "z_features = ['rb_college_weight_pounds_zscore', 'rb_college_height_inches_zscore',\n",
    "       'rb_forty_zscore', 'rb_vertical_zscore',\n",
    "       'rb_bench_zscore', 'rb_broad_zscore', 'rb_threecone_zscore',\n",
    "       'rb_shuttle_zscore', 'rb_rushing_games_zscore', \n",
    "       'rb_ann_snow_inch_zscore', 'rb_ann_rain_inch_zscore', 'rb_min_jan_zscore', 'rb_min_feb_zscore',\n",
    "       'rb_min_mar_zscore', 'rb_min_apr_zscore', 'rb_min_may_zscore',\n",
    "       'rb_min_jun_zscore', 'rb_min_jul_zscore', 'rb_min_aug_zscore',\n",
    "       'rb_min_sep_zscore', 'rb_min_oct_zscore', 'rb_min_nov_zscore',\n",
    "       'rb_min_dec_zscore', 'rb_max_jan_zscore', 'rb_max_feb_zscore',\n",
    "       'rb_max_mar_zscore', 'rb_max_apr_zscore', 'rb_max_may_zscore',\n",
    "       'rb_max_jun_zscore', 'rb_max_jul_zscore', 'rb_max_aug_zscore',\n",
    "       'rb_rushing_rec_td_zscore', 'rb_rushing_receptions_zscore', 'rb_rushing_rush_att_zscore',\n",
    "       'rb_rushing_rush_td_pg_cf_scaled_zscore',\n",
    "       'rb_rushing_rush_yds_pg_cf_scaled_zscore',\n",
    "       'rb_rushing_scrim_plays_pg_cf_scaled_zscore',\n",
    "       'rb_rushing_scrim_tds_pg_cf_scaled_zscore',\n",
    "       'rb_rushing_scrim_yds_pg_cf_scaled_zscore']\n",
    "\n",
    "limited_features = ['rb_forty_zscore', 'rb_rushing_scrim_tds_pg_cf_scaled_zscore',\n",
    "       'rb_college_weight_pounds_zscore', 'rb_vertical_zscore',\n",
    "       'rb_rushing_scrim_yds_pg_cf_scaled_zscore',\n",
    "       'rb_rushing_rush_att_zscore', 'rb_ann_rain_inch_zscore',\n",
    "       'rb_rushing_rush_td_pg_cf_scaled_zscore',\n",
    "       'rb_rushing_receptions_zscore', 'rb_bench_zscore',\n",
    "       'rb_rushing_games_zscore', 'rb_broad_zscore', 'rb_threecone_zscore',\n",
    "       'rb_rushing_scrim_plays_pg_cf_scaled_zscore',\n",
    "       'rb_college_height_inches_zscore']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Create by game by conference per game stats\n",
    "def game_avg(row):\n",
    "    stats_list = ['rushing_rec_td', 'rushing_rec_yards',\n",
    "       'rushing_receptions', 'rushing_rush_att', 'rushing_rush_td', 'rushing_rush_yds', 'rushing_scrim_plays', 'rushing_scrim_tds',\n",
    "       'rushing_scrim_yds']\n",
    "    if row['rushing_games'] == 0:\n",
    "        pass\n",
    "    else:\n",
    "        for stat in stats_list:\n",
    "            \n",
    "#{'acc', 'big_10', 'big_12', 'mountain_west', 'non_power_five', 'pac_12', 'sec'}\n",
    "            if   row['conference'] == 'sec':  row[stat] = row[stat]/row['rushing_games'] * 1\n",
    "            elif row['conference'] == 'acc':  row[stat] = row[stat]/row['rushing_games'] * .9\n",
    "            elif row['conference'] == 'big_10':  row[stat] = row[stat]/row['rushing_games'] * .9\n",
    "            elif row['conference'] == 'big_12':  row[stat] = row[stat]/row['rushing_games'] * .8\n",
    "            elif row['conference'] == 'pac_12':  row[stat] = row[stat]/row['rushing_games'] * .8\n",
    "            elif row['conference'] == 'mountain_west':  row[stat] = row[stat]/row['rushing_games'] * .75\n",
    "            elif row['conference'] == 'non_power_five':  row[stat] = row[stat]/row['rushing_games'] * .6\n",
    "        \n",
    "            \n",
    "            \n",
    "    return row\n",
    "\n",
    "\n",
    "#use by game stats?\n",
    "game_averages = 'Y'\n",
    "if game_averages == 'Y':\n",
    "    dataset = dataset.apply(game_avg, axis=1)\n",
    "else: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_list = []\n",
    "mean_list = []\n",
    "std_list = []\n",
    "col_list = []\n",
    "for col in dataset[features].columns:\n",
    "    col_list.append(col)\n",
    "    mean_list.append(dataset[col].mean())\n",
    "    std_list.append(dataset[col].std())\n",
    "df_list.append(mean_list)\n",
    "df_list.append(std_list)\n",
    "\n",
    "df_mean_std = pd.DataFrame(df_list, columns=col_list, index = ['mean', 'std'])\n",
    "df_mean_std.to_csv('rb_mean_std_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select year to hold out\n",
    "holdout_year = 2015\n",
    "#pick features from above\n",
    "features_list = limited_features\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#z_score features\n",
    "#dataset['max_madden_zscore'] = stats.zscore(dataset['max_madden'].values)\n",
    "\n",
    "#for col in dataset[features_list].columns:\n",
    "#    dataset[col] = stats.zscore(dataset[col].values)\n",
    "\n",
    "\n",
    "\n",
    "#prediction feature\n",
    "#prediction_feature = 'max_madden'\n",
    "#dataset['max_madden_zscore'] = stats.zscore(dataset['max_madden_zscore'].values)\n",
    "#max_mean = dataset['max_madden'].mean()\n",
    "#max_std = dataset['max_madden'].std()\n",
    "#prediction_feature = 'max_madden'\n",
    "\n",
    "prediction_feature = 'madden_cat'\n",
    "features_list.append(prediction_feature)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#create a train and test df based on the hold out year\n",
    "test_basis = 'hold_out'\n",
    "if test_basis == 'hold_out':\n",
    "    test_df = dataset.loc[dataset['draft_year'] == holdout_year]\n",
    "    train_df = dataset.loc[dataset['draft_year'] != holdout_year]\n",
    "\n",
    "if test_basis != 'hold_out':\n",
    "    dataset = shuffle(dataset)\n",
    "    split= .9\n",
    "    train_df = dataset[:int(dataset.shape[0]*split)]\n",
    "    test_df = dataset[int(dataset.shape[0]*split):]\n",
    "\n",
    "\n",
    "#shuffle the dataset\n",
    "test_df = shuffle(test_df)\n",
    "train_df = shuffle(train_df)\n",
    "\n",
    "#create a copy of the dataset with that feature set\n",
    "test_df_feat = test_df[features_list].copy()\n",
    "train_df_feat = train_df[features_list].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = train_df_feat[:].drop([prediction_feature], axis =1), train_df_feat.pop(prediction_feature)\n",
    "X_validation, Y_validation = test_df_feat[:].drop([prediction_feature], axis =1), test_df_feat.pop(prediction_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   # Plot feature importance\n",
    "def plot_feat_import(coef, model_title):\n",
    "    feature_coef = pd.Series(index=X_train.columns, data=coef)\n",
    "    print('{} model picked {} out of {} features'.format(model_title, str(sum(feature_coef != 0)), str(X_train.shape[1])))\n",
    "    top_bottom_10 = pd.concat([feature_coef.sort_values().head(10), feature_coef.sort_values().tail(10)])\n",
    "    #top_bottom_10 = feature_coef.sort_values()\n",
    "    top_bottom_10.plot(kind='barh', title='Feature importance (Top and bottom 10) - {} model'.format(model_title))\n",
    "    #from W207 project (Fleishman, Hilton, Niu)\n",
    "    \n",
    "def print_results(true_val, predict_val):\n",
    "    print('Accuracy:  ' + str(accuracy_score(true_val, predict_val)))\n",
    "    print('R2 : ' + str(r2_score(true_val, predict_val)))\n",
    "    print('MSE : ' + str(mean_squared_error(true_val, predict_val)))\n",
    "    \n",
    "\n",
    "def plot_confusion(mat, model):\n",
    "    \n",
    "    array = mat\n",
    "    df_cm = pd.DataFrame(array, index = [i for i in class_names],\n",
    "                      columns = [i for i in class_names])\n",
    "    plt.figure(figsize = (10,7))\n",
    "    plt.title(model)\n",
    "    sn.heatmap(df_cm, annot=True, cmap=\"Blues\")\n",
    "\n",
    "\n",
    "#https://stackoverflow.com/questions/35572000/how-can-i-plot-a-confusion-matrix\n",
    "    \n",
    "    \n",
    "class_names = sorted(list(set(dataset[prediction_feature].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(list(set(dataset[prediction_feature].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_df = test_df[['full_name', prediction_feature, 'position_group_rank']].copy()\n",
    "print(result_df)\n",
    "def result_df_viz(df, predictions, model_name):\n",
    "    \n",
    "    df[model_name] = predictions\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Adaboost\n",
    "adaboostregressor = AdaBoostRegressor(DecisionTreeRegressor(criterion='mse'), n_estimators=100, loss='linear', learning_rate=1, random_state=1)\n",
    "adaboostregressor.fit(X_train, Y_train)\n",
    "madden_predict = adaboostregressor.predict(X_validation)\n",
    "\n",
    "print_results(Y_validation, madden_predict)\n",
    "plot_feat_import(adaboostregressor.feature_importances_, 'AdaBoostRegressor')\n",
    "mat = confusion_matrix(Y_validation, madden_predict, labels = class_names)\n",
    "\n",
    "plot_confusion(mat, 'Adaboost')\n",
    "result_df_viz(result_df, madden_predict, 'AdaBoost')\n",
    "from scipy.stats import rankdata\n",
    "print(result_df.columns[3:])\n",
    "rank_df = result_df[result_df.columns[3:]]\n",
    "\n",
    "def rank(row):\n",
    "    print()\n",
    "    return row.sum()/len(row)\n",
    "result_df['rank'] = rank_df.apply(rank, axis=1)\n",
    "ordered_df = result_df[['full_name', 'AdaBoost', prediction_feature, 'position_group_rank']].sort_values(by=['AdaBoost'], ascending=False)\n",
    "ordered_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_coef = pd.Series(index=X_validation.columns, data=adaboostregressor.feature_importances_)\n",
    "feature_coef  = feature_coef.sort_values(ascending=False)\n",
    "print(feature_coef.index)\n",
    "feature_coef.to_csv('rb_feature_importance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_df.to_csv('rank_of_picks.csv')\n",
    "file_name = 'rb_model.pkl'\n",
    "joblib.dump(adaboostregressor, file_name)\n",
    "\n",
    "\n",
    "\n",
    "#https://www.kaggle.com/prmohanty/python-how-to-save-and-load-ml-models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
